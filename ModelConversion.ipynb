{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ModelConversion.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPMsSmEhVdwe1KFhWCFN5/B"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Below is the docker file. Install the requirements as per imports."],"metadata":{"id":"3dCEvLEEZpsO"}},{"cell_type":"code","source":["FROM pytorch/pytorch:1.9.0-cuda10.2-cudnn7-runtime\n","\n","ARG model_conv_file='model_conv.py'\n","\n","RUN apt-get update\n","RUN apt-get install -y libgl1-mesa-glx git protobuf-compiler\n","RUN apt update && apt install -y libsm6 libxext6\n","RUN apt-get install -y libxrender-dev\n","RUN apt-get install -y libglib2.0-0\n","\n","RUN mkdir -p /root/Documents/\n","\n","WORKDIR /root/Documents/\n","COPY requirements.txt /root/Documents/requirements.txt\n","RUN python -m pip install --upgrade pip\n","RUN pip install -r requirements.txt\n","\n","COPY ${model_conv_file} /root/Documents/model_conv.py\n","\n","\n","ENV PYTHONPATH=\"/root/Documents/\"\n","# CMD [\"python3\", \"model_conv.py\", \"--saved-model\", \"mobilenetv2_model.pt\", \"--output\", \"mobilenetv2_model.onnx\"]\n","ENTRYPOINT [ \"python3\", \"model_conv.py\" ]"],"metadata":{"id":"SRcnCFw71BCy"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"19QntjQN09gx"},"outputs":[],"source":["from typing import Optional\n","import os\n","\n","import sys\n","import shutil\n","import logging\n","import cv2\n","import numpy as np\n","import json\n","\n","import tfcoreml\n","import argparse\n","import coremltools as ct\n","import onnxmltools\n","import onnx\n","from onnx2pytorch import ConvertModel\n","from onnx_tf.backend import prepare\n","import torch\n","# import keras_retinanet\n","# import keras_retinanet.layers, keras_retinanet.losses\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import load_model\n","\n","from torch.utils.mobile_optimizer import optimize_for_mobile\n","import inspect\n","from onnx import numpy_helper\n","from onnx2keras.layers import AVAILABLE_CONVERTERS\n","\n","from tf2onnx.convert import get_args\n","from tf2onnx.tf_loader import from_saved_model\n","from tf2onnx.utils import save_protobuf, save_onnx_zip, set_debug_mode\n","from tf2onnx.constants import ENV_TF2ONNX_CATCH_ERRORS\n","from tf2onnx.optimizer import optimize_graph\n","from tf2onnx.tf_utils import compress_graph_def\n","from tf2onnx.graph import ExternalTensorStorage\n","from tf2onnx.tfonnx import process_tf_graph\n","from tf2onnx.verbose_logging import get_verbosity_level\n","\n","\n","######################################## Common Functions ##################################################\n","\n","def set_logging(name=None, verbose=True):\n","    # Sets level and returns logger\n","    rank = int(os.getenv('RANK', -1))  # rank in world for Multi-GPU trainings\n","    logging.basicConfig(format=\"%(message)s\", level=logging.INFO if (verbose and rank in (-1, 0)) else logging.WARNING)\n","    return logging.getLogger(name)\n","\n","def make_default_custom_op_handler(domain):\n","    def default_custom_op_handler(ctx, node, name, args):\n","        node.domain = domain\n","        return node\n","    return default_custom_op_handler\n","\n","def onnx_node_attributes_to_dict(args):\n","    \"\"\"\n","    Parse ONNX attributes to Python dictionary\n","    :param args: ONNX attributes object\n","    :return: Python dictionary\n","    \"\"\"\n","    def onnx_attribute_to_dict(onnx_attr):\n","        \"\"\"\n","        Parse ONNX attribute\n","        :param onnx_attr: ONNX attribute\n","        :return: Python data type\n","        \"\"\"\n","        if onnx_attr.HasField('t'):\n","            return numpy_helper.to_array(getattr(onnx_attr, 't'))\n","\n","        for attr_type in ['f', 'i', 's']:\n","            if onnx_attr.HasField(attr_type):\n","                return getattr(onnx_attr, attr_type)\n","\n","        for attr_type in ['floats', 'ints', 'strings']:\n","            if getattr(onnx_attr, attr_type):\n","                return list(getattr(onnx_attr, attr_type))\n","    return {arg.name: onnx_attribute_to_dict(arg) for arg in args}\n","\n","def _onnx_to_keras(onnx_model, input_names,\n","                  input_shapes=None, name_policy=None, verbose=True, change_ordering=False):\n","    \"\"\"\n","    Convert ONNX graph to Keras model format\n","    :param onnx_model: loaded ONNX model\n","    :param input_names: list with input names\n","    :param input_shapes: override input shapes (experimental)\n","    :param name_policy: override layer names. None, \"short\" or \"renumerate\" (experimental)\n","    :param verbose: verbose output\n","    :param change_ordering: change ordering to HWC (experimental)\n","    :return: Keras model\n","    \"\"\"\n","    # Use channels first format by default.\n","    keras_fmt = keras.backend.image_data_format()\n","    keras.backend.set_image_data_format('channels_first')\n","\n","    if verbose:\n","        logging.basicConfig(level=logging.DEBUG)\n","\n","    # logger = logging.getLogger('onnx2keras')\n","\n","    onnx_weights = onnx_model.graph.initializer\n","    onnx_inputs = onnx_model.graph.input\n","    onnx_outputs = [i.name for i in onnx_model.graph.output]\n","    onnx_nodes = onnx_model.graph.node\n","\n","    LOGGER.info('List input shapes:')\n","    LOGGER.info(input_shapes)\n","\n","    LOGGER.debug('List inputs:')\n","    for i, input in enumerate(onnx_inputs):\n","        LOGGER.info('Input {0} -> {1}.'.format(i, input.name))\n","\n","    LOGGER.info('List outputs:')\n","    for i, output in enumerate(onnx_outputs):\n","        LOGGER.info('Output {0} -> {1}.'.format(i, output))\n","\n","    LOGGER.info('Gathering weights to dictionary.')\n","    weights = {}\n","    for onnx_w in onnx_weights:\n","        try:\n","            if len(onnx_w.ListFields()) < 4:\n","                onnx_extracted_weights_name = onnx_w.ListFields()[1][1]\n","            else:\n","                onnx_extracted_weights_name = onnx_w.ListFields()[2][1]\n","            weights[onnx_extracted_weights_name] = numpy_helper.to_array(onnx_w)\n","        except:\n","            onnx_extracted_weights_name = onnx_w.ListFields()[3][1]\n","            weights[onnx_extracted_weights_name] = numpy_helper.to_array(onnx_w)\n","\n","        LOGGER.info('Found weight {0} with shape {1}.'.format(\n","                     onnx_extracted_weights_name,\n","                     weights[onnx_extracted_weights_name].shape))\n","\n","    layers = dict()\n","    lambda_funcs = dict()\n","    keras_outputs = []\n","    keras_inputs = []\n","\n","    for i, input_name in enumerate(input_names):\n","        for onnx_i in onnx_inputs:\n","            if onnx_i.name == input_name:\n","                if input_shapes:\n","                    input_shape = input_shapes[i]\n","                else:\n","                    input_shape = [i.dim_value for i in onnx_i.type.tensor_type.shape.dim][1:]\n","\n","                layers[input_name] = keras.layers.InputLayer(\n","                    input_shape=input_shape, name=input_name\n","                ).output\n","\n","                keras_inputs.append(layers[input_name])\n","\n","                LOGGER.info('Found input {0} with shape {1}'.format(input_name, input_shape))\n","\n","    # Convert every operation separable\n","    node_names = []\n","    for node_index, node in enumerate(onnx_nodes):\n","        node_type = node.op_type\n","        node_params = onnx_node_attributes_to_dict(node.attribute)\n","\n","        # Add global converter info:\n","        node_params['change_ordering'] = change_ordering\n","        node_params['name_policy'] = name_policy\n","\n","        node_name = str(node.output[0])\n","        keras_names = []\n","        for output_index, output in enumerate(node.output):\n","            if name_policy == 'short':\n","                keras_name = keras_name_i = str(output)[:8]\n","                suffix = 1\n","                while keras_name_i in node_names:\n","                    keras_name_i = keras_name + '_' + str(suffix)\n","                    suffix += 1\n","                keras_names.append(keras_name_i)\n","            elif name_policy == 'renumerate':\n","                postfix = node_index if len(node.output) == 1 else \"%s_%s\" % (node_index, output_index)\n","                keras_names.append('LAYER_%s' % postfix)\n","            else:\n","                keras_names.append(output)\n","\n","        if len(node.output) != 1:\n","            LOGGER.warning('Trying to convert multi-output node')\n","            node_params['_outputs'] = list(node.output)\n","            node_names.extend(keras_names)\n","        else:\n","            keras_names = keras_names[0]\n","            node_names.append(keras_names)\n","\n","        # If needed more conversion info, enable it\n","        # LOGGER.info('######')\n","        # LOGGER.info('...')\n","        # LOGGER.info('Converting ONNX operation')\n","        # LOGGER.info('type: %s', node_type)\n","        # LOGGER.info('node_name: %s', node_name)\n","        # LOGGER.info('node_params: %s', node_params)\n","        # LOGGER.info('...')\n","\n","        LOGGER.info('Check if all inputs are available:')\n","        if len(node.input) == 0 and node_type != 'Constant':\n","            raise AttributeError('Operation doesn\\'t have an input. Aborting.')\n","\n","        for i, node_input in enumerate(node.input):\n","            LOGGER.info('Check input %i (name %s).', i, node_input)\n","            if node_input not in layers:\n","                LOGGER.info('The input not found in layers / model inputs.')\n","\n","                if node_input in weights:\n","                    LOGGER.info('Found in weights, add as a numpy constant.')\n","                    layers[node_input] = weights[node_input]\n","                else:\n","                    raise AttributeError('Current node is not in weights / model inputs / layers.')\n","        else:\n","            LOGGER.info('... found all, continue')\n","\n","        keras.backend.set_image_data_format('channels_first')\n","        if node_type == 'Clip': # Add more node types manually if it is failing; higher chances of failing while the conversion is being done\n","            node_params['min']=0\n","            node_params['max']=None\n","        AVAILABLE_CONVERTERS[node_type](\n","            node,\n","            node_params,\n","            layers,\n","            lambda_funcs,\n","            node_name,\n","            keras_names\n","        )\n","        if isinstance(keras_names, list):\n","            keras_names = keras_names[0]\n","\n","        try:\n","            LOGGER.info('Output TF Layer -> ' + str(layers[keras_names]))\n","        except KeyError:\n","            pass\n","\n","    # Check for terminal nodes\n","    for layer in onnx_outputs:\n","        if layer in layers:\n","            keras_outputs.append(layers[layer])\n","\n","    # Create model\n","    model = keras.models.Model(inputs=keras_inputs, outputs=keras_outputs)\n","\n","    if change_ordering:\n","        import numpy as np\n","        conf = model.get_config()\n","\n","        for layer in conf['layers']:\n","            if layer['config'] and 'shared_axes' in layer['config']:\n","                # TODO: check axes first (if it's not 4D tensor)\n","                layer['config']['shared_axes'] = [1, 2]\n","\n","            if layer['config'] and 'batch_input_shape' in layer['config']:\n","                layer['config']['batch_input_shape'] = \\\n","                    tuple(np.reshape(np.array(\n","                        [\n","                            [None] +\n","                            list(layer['config']['batch_input_shape'][2:][:]) +\n","                            [layer['config']['batch_input_shape'][1]]\n","                        ]), -1\n","                    ))\n","            if layer['config'] and 'target_shape' in layer['config']:\n","                if len(list(layer['config']['target_shape'][1:][:])) > 0:\n","                    layer['config']['target_shape'] = \\\n","                        tuple(np.reshape(np.array(\n","                                list(layer['config']['target_shape'][1:]) +\n","                                [layer['config']['target_shape'][0]]\n","                            ), -1),)\n","\n","            if layer['config'] and 'data_format' in layer['config']:\n","                layer['config']['data_format'] = 'channels_last'\n","            if layer['config'] and 'axis' in layer['config']:\n","                if layer['config']['axis'] == 3:\n","                    layer['config']['axis'] = 1\n","                if layer['config']['axis'] == 1:\n","                    layer['config']['axis'] = 3\n","\n","        for layer in conf['layers']:\n","            if 'function' in layer['config'] and layer['config']['function'][1] is not None:\n","                kerasf = list(layer['config']['function'])\n","                dargs = list(kerasf[1])\n","                func = lambda_funcs.get(layer['name'])\n","\n","                if func:\n","                    if len(dargs) > 1:\n","                        params = inspect.signature(func).parameters\n","                        i = list(params.keys()).index('axes') if ('axes' in params) else -1\n","\n","                        if i > 0:\n","                            i -= 1\n","                            axes = list(range(len(dargs[i].shape)))\n","                            axes = axes[0:1] + axes[2:] + axes[1:2]\n","                            dargs[i] = np.transpose(dargs[i], axes)\n","\n","                        i = list(params.keys()).index('axis') if ('axis' in params) else -1\n","\n","                        if i > 0:\n","                            i -= 1\n","                            axis = np.array(dargs[i])\n","                            axes_map = np.array([0, 3, 1, 2])\n","                            dargs[i] = axes_map[axis]\n","                    else:\n","                        if dargs[0] == -1:\n","                            dargs = [1]\n","                        elif dargs[0] == 3:\n","                            dargs = [1]\n","\n","                kerasf[1] = tuple(dargs)\n","                layer['config']['function'] = tuple(kerasf)\n","\n","        keras.backend.set_image_data_format('channels_last')\n","        model_tf_ordering = keras.models.Model.from_config(conf)\n","\n","        for dst_layer, src_layer, conf in zip(model_tf_ordering.layers, model.layers, conf['layers']):\n","            W = src_layer.get_weights()\n","            # TODO: check axes first (if it's not 4D tensor)\n","            if conf['config'] and 'shared_axes' in conf['config']:\n","                W[0] = W[0].transpose(1, 2, 0)\n","            dst_layer.set_weights(W)\n","\n","        model = model_tf_ordering\n","\n","    keras.backend.set_image_data_format(keras_fmt)\n","\n","    return model\n","\n","def convert_common(frozen_graph, name=\"unknown\", large_model=False, output_path=None,\n","                    output_frozen_graph=None, custom_ops=None, custom_op_handlers=None, **kwargs):\n","    \"\"\"Common processing for conversion.\"\"\"\n","    \n","    model_proto = None\n","    external_tensor_storage = None\n","    const_node_values = None\n","\n","    if custom_ops is not None:\n","        if custom_op_handlers is None:\n","            custom_op_handlers = {}\n","        custom_op_handlers.update(\n","            {op: (make_default_custom_op_handler(domain), []) for op, domain in custom_ops.items()})\n","\n","    with tf.Graph().as_default() as tf_graph:\n","        if large_model:\n","            const_node_values = compress_graph_def(frozen_graph)\n","            external_tensor_storage = ExternalTensorStorage()\n","        if output_frozen_graph:\n","            save_protobuf(output_frozen_graph, frozen_graph)\n","        if not kwargs.get(\"tflite_path\") and not kwargs.get(\"tfjs_path\"):\n","            tf.import_graph_def(frozen_graph, name='')\n","        g = process_tf_graph(tf_graph, const_node_values=const_node_values,\n","                             custom_op_handlers=custom_op_handlers, **kwargs)\n","        if ENV_TF2ONNX_CATCH_ERRORS in os.environ:\n","            catch_errors = ENV_TF2ONNX_CATCH_ERRORS.upper() == \"TRUE\"\n","        else:\n","            catch_errors = not large_model\n","        onnx_graph = optimize_graph(g, catch_errors)\n","        model_proto = onnx_graph.make_model(\"converted from {}\".format(name),\n","                                            external_tensor_storage=external_tensor_storage)\n","    if output_path:\n","        if large_model:\n","            save_onnx_zip(output_path, model_proto, external_tensor_storage)\n","        else:\n","            save_protobuf(output_path, model_proto)\n","\n","    return model_proto, external_tensor_storage\n","\n","def load_sample_input(\n","            file_path: Optional[str] = None,\n","            target_shape: tuple = (224, 224, 3),\n","            seed: int = 10,\n","            normalize: bool = True\n","    ):\n","        if file_path is not None:\n","            # pass\n","            if (len(target_shape) == 3 and target_shape[-1] == 1) or len(target_shape) == 2:\n","                imread_flags = cv2.IMREAD_GRAYSCALE\n","            elif len(target_shape) == 3 and target_shape[-1] == 3:\n","                imread_flags = cv2.IMREAD_COLOR\n","            else:\n","                imread_flags = cv2.IMREAD_ANYCOLOR + cv2.IMREAD_ANYDEPTH\n","            try:\n","                img = cv2.resize(\n","                    src=cv2.imread(file_path, imread_flags),\n","                    dsize=target_shape[:2],\n","                    interpolation=cv2.INTER_LINEAR\n","                )\n","                if len(img.shape) == 3:\n","                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","                if normalize:\n","                    img = img * 1. / 255\n","                img = img.astype(np.float32)\n","\n","                sample_data_np = np.transpose(img, (2, 0, 1))[np.newaxis, :, :, :]\n","                sample_data_torch = torch.from_numpy(sample_data_np)\n","                logging.info(f'Sample input successfully loaded from, {file_path}')\n","\n","            except Exception:\n","                logging.error(f'Can not load sample input from, {file_path}')\n","                sys.exit(-1)\n","\n","        else:\n","            logging.info(f'Sample input file path not specified, random data will be generated')\n","            np.random.seed(seed)\n","            data = np.random.random(target_shape).astype(np.float32)\n","            sample_data_np = np.transpose(data, (2, 0, 1))[np.newaxis, :, :, :]\n","            sample_data_torch = torch.from_numpy(sample_data_np)\n","            logging.info(f'Sample input randomly generated')\n","\n","        return {'sample_data_np': sample_data_np, 'sample_data_torch': sample_data_torch}\n","\n","########################################## Class for conversion ################################################\n","\n","class ModelConversion:\n","    def __init__(\n","            self,\n","            saved_model: str,\n","            output: str,\n","            sample_file_path: Optional[str] = None,\n","            target_shape: tuple = (224, 224, 3),\n","            seed: int = 10,\n","            normalize: bool = True,\n","            opset: int = 13\n","    ):\n","        self.saved_model = saved_model  # initial model path\n","        self.output = output # final model path\n","\n","        self.sample_file_path = sample_file_path\n","        self.target_shape = target_shape\n","        self.seed = seed\n","        self.normalize = normalize\n","        self.device = 'cpu'\n","        self.tmpdir = os.path.join(os.getcwd(),'model_conv')\n","        self.__check_tmpdir()\n","        self.temp_torch_path = os.path.join(self.tmpdir, 'temp_torch.pt')\n","        self.temp_onnx_path = os.path.join(self.tmpdir, 'temp_onnx.onnx')\n","        self.temp_coreml_path = os.path.join(self.tmpdir, 'temp_coreml.mlmodel')\n","        self.temp_keras_path = os.path.join(self.tmpdir, 'temp_keras.h5')\n","        self.temp_tf_path = os.path.join(self.tmpdir, 'tf_temp_model')\n","        self.func = ''\n","        self.final = ''\n","        self.infunc = ''\n","        self.opset = opset\n","\n","        if os.path.dirname(self.output) == '':\n","            self.output = os.path.join(self.tmpdir, self.output)\n","\n","    def log_info(self):\n","        LOGGER.info(f' -------- Conversion \"{self.infunc}\" is done and the model was saved at: {self.final} --------')\n","        \n","    def __check_tmpdir(self):\n","        try:\n","            if os.path.exists(self.tmpdir) and os.path.isdir(self.tmpdir):\n","                shutil.rmtree(self.tmpdir)\n","                logging.info(f'Old temp directory removed')\n","            os.makedirs(self.tmpdir, exist_ok=True)\n","            logging.info(f'Temp directory created at {self.tmpdir}')\n","        except Exception:\n","            logging.error('Can not create temporary directory, exiting!')\n","            sys.exit(-1)\n","    \n","    def load_torch_model(self, torch_model_path) -> torch.nn.Module:\n","        try:\n","            if torch_model_path.endswith('.pth') or torch_model_path.endswith('.pt'):\n","                model = torch.load(torch_model_path, map_location=self.device)\n","                # model = model.eval()\n","                logging.info('PyTorch model successfully loaded and mapped to CPU')\n","                return model\n","            else:\n","                logging.error('Specified file path not compatible with torch2tflite, exiting!')\n","                sys.exit(-1)\n","        except Exception:\n","            logging.error('Can not load PyTorch model. Please make sure'\n","                          'that model saved like `torch.save(model, PATH)`')\n","            sys.exit(-1)\n","\n","    def torch_to_torchscript(self, model, output, optimize=False) -> None :\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        model = self.load_torch_model(model)\n","        im = torch.zeros(1, 3, *self.target_shape[:-1]).to(self.device)  #\n","        LOGGER.info(f'\\n starting export with torch {torch.__version__}...')\n","        ts = torch.jit.trace(model, im, strict=False)\n","        d = {\"shape\": im.shape}\n","        extra_files = {'config.txt': json.dumps(d)}  # torch._C.ExtraFilesMap()\n","        (optimize_for_mobile(ts) if optimize else ts).save(str(output), _extra_files=extra_files)\n","        self.log_info()\n","        \n","    def torch_to_onnx(self, input, output) -> None:\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        # args.saved_model=torchvision.models.mobilenet_v2(pretrained = True, progress = True)\n","        # input=args.saved_model\n","        model = self.load_torch_model(input)\n","        sample_data = load_sample_input(self.sample_file_path, self.target_shape, self.seed, self.normalize)\n","        torch.onnx.export(\n","            model=model,\n","            args=sample_data['sample_data_torch'],\n","            f=output,\n","            verbose=False,\n","            export_params=True,\n","            do_constant_folding=False,\n","            input_names=['input'],\n","            opset_version=self.opset,\n","            output_names=['output'],\n","            )\n","        self.log_info()\n","\n","    def tf_to_onnx(self, input, output) -> None:\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        args = get_args()\n","        logging.basicConfig(level=get_verbosity_level(args.verbose))\n","        if args.debug:\n","            set_debug_mode(True)\n","\n","        # logger = logging.getLogger(TF2ONNX_PACKAGE_NAME)\n","\n","        args.saved_model = os.path.dirname(input)\n","        args.output = output\n","        args.opset = self.opset\n","        tensors_to_rename = {}\n","        graph_def = None\n","        inputs = None\n","        outputs = None\n","        model_path = None\n","\n","        if args.rename_inputs:\n","            tensors_to_rename.update(zip(inputs, args.rename_inputs))\n","        if args.rename_outputs:\n","            tensors_to_rename.update(zip(outputs, args.rename_outputs))\n","        graph_def, inputs, outputs, initialized_tables, tensors_to_rename = from_saved_model(\n","                args.saved_model, args.inputs, args.outputs, args.tag, args.signature_def, args.concrete_function,\n","                args.large_model, return_initialized_tables=True, return_tensors_to_rename=True,\n","                use_graph_names=args.use_graph_names)\n","        model_path = args.saved_model\n","\n","        with tf.device(\"/cpu:0\"):\n","            model_proto, _ = convert_common(\n","            graph_def,\n","            name=model_path,\n","            continue_on_error=args.continue_on_error,\n","            target=args.target,\n","            opset=args.opset,\n","            shape_override=args.shape_override,\n","            input_names=inputs,\n","            output_names=outputs,\n","            inputs_as_nchw=args.inputs_as_nchw,\n","            large_model=args.large_model,\n","            tensors_to_rename=tensors_to_rename,\n","            ignore_default=args.ignore_default,\n","            use_default=args.use_default,\n","            dequantize=args.dequantize,\n","            initialized_tables=initialized_tables,\n","            output_frozen_graph=args.output_frozen_graph,\n","            output_path=args.output)\n","\n","        # LOGGER.info(\"\")\n","        # LOGGER.info(\"Successfully converted TensorFlow model %s to ONNX\", model_path)\n","        self.log_info()\n","\n","        LOGGER.info(\"Model inputs: %s\", [n.name for n in model_proto.graph.input])\n","        LOGGER.info(\"Model outputs: %s\", [n.name for n in model_proto.graph.output])\n","        if args.output:\n","            if args.large_model:\n","                LOGGER.info(\"Zipped ONNX model is saved at %s. Unzip before opening in onnxruntime.\", output)\n","            else:\n","                LOGGER.info(\"ONNX model is saved at %s\", args.output)\n","        else:\n","            LOGGER.info(\"To export ONNX model to file, please run with `--output` option\")\n","\n","    def onnx_to_tf(self, input, output) -> None:\n","        if os.path.dirname(output) == '':\n","            output = os.path.join(self.tmpdir, output)\n","        if output.endswith('.pb'):\n","            output = os.path.splitext(output)[0]\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        onnx_model = onnx.load(input)\n","        onnx.checker.check_model(onnx_model)\n","        tf_rep = prepare(onnx_model)\n","        tf_rep.export_graph(output)\n","        self.log_info()\n","\n","    def tf_to_tflite(self, input, output) -> None:\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        input = os.path.dirname(input) if not os.path.isdir(input) else input # in intermediate calls directory is being passed and .pb path\n","        converter = tf.lite.TFLiteConverter.from_saved_model(input)\n","        tflite_model = converter.convert()\n","        with open(output, 'wb') as f:\n","            f.write(tflite_model)\n","        self.log_info()\n","\n","    def keras_to_onnx(self, input, output) -> None:\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        keras_model = load_model(input)\n","\n","        ## Enable this if the model contains custome objects like keras retinanet\n","        # keras_model = load_model(input, custom_objects={'UpsampleLike':keras_retinanet.layers.UpsampleLike,\n","        # '_smooth_l1':keras_retinanet.losses.smooth_l1(), '_focal': keras_retinanet.losses.focal()})\n","\n","        onnx_model = onnxmltools.convert_keras(keras_model)\n","        onnxmltools.utils.save_model(onnx_model, output)\n","        self.log_info()\n","\n","    def onnx_to_torch(self, input, output) -> None:\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        onnx_model = onnx.load(input)\n","        pytorch_model = ConvertModel(onnx_model)\n","        torch.save(pytorch_model.state_dict(), output)\n","        self.log_info()\n","\n","    def coreml_to_onnx(self, input, output) -> None:\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        coreml_model = ct.utils.load_spec(input)\n","        onnx_model = onnxmltools.convert_coreml(coreml_model)\n","        onnxmltools.utils.save_model(onnx_model, output)\n","        self.log_info()\n","\n","    def onnx_to_coreml(self, input, output) -> None:\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        model = ct.converters.onnx.convert(model=input)\n","        model.save(output)\n","        self.log_info()\n","\n","    def tf_to_coreml(self, input, output) -> None:\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        # input = os.path.dirname(input) if not os.path.isdir(input) else input # in intermediate calls directory is being passed and .pb path\n","        tfcoreml.convert(tf_model_path=input, ## check here if dir or .pb path\n","                    mlmodel_path=output,\n","                    output_feature_names=['softmax:0'],  # name of the output tensor (appended by \":0\")\n","                    input_name_shape_dict={'input:0': [1, *self.target_shape]},  # map from input tensor name (placeholder op in the graph) to shape\n","                   ) # one of ['12', '11.2']\n","        self.log_info()\n","    \n","    def onnx_to_keras(self, input, output) -> None:\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        onnx_model = onnx.load(input)\n","        input_shapes = self.target_shape[::-1]\n","        k_model = _onnx_to_keras(onnx_model=onnx_model, input_names=['input'],input_shapes=[input_shapes])\n","        keras.models.save_model(k_model, output, overwrite=True,include_optimizer=True)\n","        self.log_info()\n","\n","    def keras_to_tf(self, input, output) -> None:\n","        if os.path.dirname(output) == '':\n","            output = os.path.join(self.tmpdir, output)\n","        if output.endswith('.pb'):\n","            output = os.path.splitext(output)[0]\n","        self.final = output\n","        self.infunc = inspect.currentframe().f_code.co_name\n","        model = load_model(input)\n","        model.save(output)\n","        self.log_info()\n","\n","    ########### Combinations ###########\n","    def torch_to_coreml(self, input, output) -> None:\n","        self.final = output\n","        self.torch_to_onnx(input, self.temp_onnx_path)\n","        self.onnx_to_coreml(self.temp_onnx_path, output)        \n","\n","    def torch_to_tflite(self, input, output) -> None:\n","        self.final = output\n","        self.torch_to_tf(input, self.temp_tf_path)\n","        self.tf_to_tflite(self.temp_tf_path, output)\n","\n","    def torch_to_keras(self, input, output) -> None:\n","        self.final = output\n","        self.torch_to_onnx(input, self.temp_onnx_path)\n","        self.onnx_to_keras(self.temp_onnx_path, output)\n","\n","    def keras_to_torch(self, input, output) -> None:\n","        self.final = output\n","        self.keras_to_onnx(input, self.temp_onnx_path)\n","        self.onnx_to_torch(self.temp_onnx_path, output)\n"," \n","    def torch_to_tf(self, input, output) -> None:\n","        self.final = output\n","        self.torch_to_onnx(input, self.temp_onnx_path)\n","        self.onnx_to_tf(self.temp_onnx_path, output)\n","\n","    def coreml_to_tf(self, input, output) -> None:\n","        self.final = output\n","        self.coreml_to_onnx(input, self.temp_onnx_path)\n","        self.onnx_to_tf(self.temp_onnx_path, output)\n","    ########### Combinations ###########\n","\n","    function_mappings = {   # You can always add here new function and its body as above\n","            'torch_to_onnx':torch_to_onnx,  # working\n","            'tf_to_onnx':tf_to_onnx,    # working\n","            'keras_to_onnx':keras_to_onnx,  # working\n","            'coreml_to_onnx':coreml_to_onnx, # working\n","            'onnx_to_tf':onnx_to_tf,   # working\n","            'onnx_to_keras':onnx_to_keras,  # working\n","            'onnx_to_torch':onnx_to_torch,   # working\n","            'coreml_to_tf':coreml_to_tf,    #'''model type issue, float 32 and 64 '''\n","            'onnx_to_coreml':onnx_to_coreml,    # working\n","            'tf_to_tflite':tf_to_tflite,    # working\n","            'tf_to_coreml':tf_to_coreml,    #'''DOABLE, lib is old, it calls tf.graph() directly, so tf 2 doesnt work '''\n","            'torch_to_tflite':torch_to_tflite,  # working\n","            'torch_to_tf':torch_to_tf,  # working\n","            'torch_to_torchscript':torch_to_torchscript,  # working\n","            'torch_to_coreml':torch_to_coreml,  # working\n","            'keras_to_torch':keras_to_torch, # working\n","            'torch_to_keras':torch_to_keras, # working\n","            'keras_to_tf':keras_to_tf,  # working\n","            } \n","\n","    ext_mappings = {    # Add new extensions below if not present\n","            'pb':'tf',\n","            'h5':'keras',\n","            'pt':'torch',\n","            'pth':'torch', \n","            'tflite':'tflite',\n","            'mlmodel':'coreml',\n","            'onnx':'onnx',\n","            'torchscript':'torchscript',\n","    }\n","\n","    def convert(self) -> None:\n","        model_ext = os.path.splitext(self.saved_model)[1][1:]\n","        output_ext = os.path.splitext(self.output)[1][1:]\n","        \n","        assert len(model_ext) > 0, f'ERROR: The given \"saved-model\" is not a file. It doesnt have an extension at the end: {self.saved_model}.'\n","        assert len(output_ext) > 0, f'ERROR: The requested \"output\" is not a file. It doesnt have an extension at the end: {self.output}.'\n","        try:\n","            model_ext = self.ext_mappings[model_ext]\n","            output_ext = self.ext_mappings[output_ext]\n","        except KeyError:\n","            LOGGER.error(f'ERROR: Invalid extension key given either for the saved-model or for the output \"model_extension: {model_ext}, output_extension: {output_ext}\". Valid extensions are: {self.ext_mappings.keys()}')\n","            sys.exit(1)\n","        func = model_ext + '_to_' + output_ext\n","        try:\n","            self.func = self.function_mappings[func]\n","        except KeyError:\n","                LOGGER.error(f'ERROR: Invalid conversion requested, try again. The valid conversions are: {self.function_mappings.keys()}')\n","                sys.exit(1)\n","        LOGGER.info(f'          <--------> RUNNING THE CONVERSION: {self.func.__name__} <-------->          ')\n","        self.func(self, self.saved_model, self.output)\n","\n","\n","############################################  MAIN  ##############################################\n","# Both --saved-model and --output should be provided with extensions just like source and destination; It can be along with directories or just the file names\n","# for e.g  'python model_conv.py --saved-model /path/to/model.pb --output model.onnx'  --> This will convert the tf saved model to onnx format\n","\n","if __name__ == '__main__':\n","    LOGGER = set_logging(__name__)\n","     \n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('--saved-model', type=str, required=True, help='available formats are (.onnx, .mlmodel(coreml), .pt(torch), .pth(torch), .pb(tf), .tflite, .h5(keras) )')\n","    parser.add_argument('--output', type=str, required=True)\n","    parser.add_argument('--target-shape', type=tuple, nargs=3, default=(224, 224, 3))\n","    parser.add_argument('--opset', type=int, default=13, help='ONNX: opset version')\n","    parser.add_argument('--sample-file', type=str)\n","    \n","    args = parser.parse_args()\n","    conv_model = ModelConversion(args.saved_model, args.output, opset=args.opset)\n","    conv_model.convert()\n","    final_model = conv_model.final\n","    \n","    if os.path.isdir(final_model):\n","        flag = False\n","        for fname in os.listdir(final_model):\n","            if fname.endswith('.pb'):\n","                flag = True\n","                LOGGER.info(f'Final model is saved at: {os.path.join(final_model, fname)}')\n","                break   \n","        if not flag:\n","            raise Exception(f'ERROR: No model with required extension is found at: {final_model}')   \n","    elif os.path.isfile(final_model) and (os.path.splitext(args.output)[1][1:] == os.path.splitext(final_model)[1][1:] ):\n","        LOGGER.info(f'Final model is saved at: {os.path.join(final_model)}')   \n","    else:\n","        raise Exception(f'ERROR: No model with required extension is found at: {final_model}')   \n","    \n"]}]}